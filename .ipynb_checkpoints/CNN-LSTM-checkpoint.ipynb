{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 1, 95)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build character map function for encoding URL string\n",
    "\n",
    "import string\n",
    "ascii_letters = string.ascii_letters # 1~52\n",
    "digits = string.digits # 53~62\n",
    "punctuation = string.punctuation # 63~94\n",
    "total_char = ascii_letters + digits + punctuation    \n",
    "\n",
    "UNKNOWN_CHAR = len(total_char) + 1\n",
    "TOTAL_FEATURES = UNKNOWN_CHAR + 1 # include the default padding integer 0 \n",
    "charmap = {\n",
    "    c: idx+1\n",
    "    for idx, c in enumerate(total_char)\n",
    "}\n",
    "\n",
    "def encodeChar(c):\n",
    "    return charmap.get(c, UNKNOWN_CHAR)\n",
    "\n",
    "encodeChar(\"x\"), encodeChar(\"a\"), encodeChar(\"æˆ‘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "import pandas\n",
    "import statistics\n",
    "df = pandas.read_csv(\"all_urls.csv\")\n",
    "\n",
    "df[\"len\"] = df.url.apply(lambda s: len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    23007.000000\n",
       "mean       116.103099\n",
       "std        114.441389\n",
       "min         15.000000\n",
       "25%         45.000000\n",
       "50%         79.000000\n",
       "75%        140.000000\n",
       "max       1641.000000\n",
       "Name: len, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the length stats\n",
    "df.len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=200 18.16404%\n",
      "x=300 4.48994%\n",
      "x=400 2.16891%\n",
      "x=500 1.51693%\n",
      "x=600 1.19094%\n",
      "x=700 0.52593%\n",
      "x=800 0.25644%\n",
      "x=900 0.19559%\n",
      "x=1000 0.10432%\n"
     ]
    }
   ],
   "source": [
    "# find a Length for large coverage for all sample URL\n",
    "# Length = 400 has ~98% coverage\n",
    "for t in [200, 300, 400, 500, 600, 700, 800, 900, 1000]:\n",
    "    print(\"x={} {:.5f}%\".format(t, 100 * sum(df.len.apply(lambda x: x > t)) / len(df.len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "6000 train sequences\n",
      "2000 test sequences\n",
      "2000 val sequences\n"
     ]
    }
   ],
   "source": [
    "# sampling train/test dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sub_df = df.sample(10000)\n",
    "url_train, url_test, y_train, y_test \\\n",
    "    = train_test_split(sub_df.url, sub_df.label, test_size=0.2, random_state=1)\n",
    "\n",
    "url_train, url_val, y_train, y_val \\\n",
    "    = train_test_split(url_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "print('Loading data...')\n",
    "print(len(url_train), 'train sequences')\n",
    "print(len(url_test), 'test sequences')\n",
    "print(len(url_val), 'val sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some configurations \n",
    "\n",
    "# Embedding\n",
    "max_features = TOTAL_FEATURES\n",
    "maxlen = 400 # ~98% coverage, paper uses 96% coverage\n",
    "embedding_size = 128\n",
    "\n",
    "# Training\n",
    "batch_size = 64 # paper param\n",
    "epochs = 20 # paper param\n",
    "\n",
    "# Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 2\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Dropout ratio\n",
    "Dropout_ratio = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (6000, 400)\n",
      "x_test shape: (2000, 400)\n",
      "x_val shape: (2000, 400)\n"
     ]
    }
   ],
   "source": [
    "# encode the URL by one-hot encoding and padding feature vector by 'pre'\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "\n",
    "x_train = pad_sequences(url_train.apply(lambda url: numpy.array([encodeChar(c) for c in url])), \n",
    "              maxlen=maxlen, \n",
    "              padding='pre')\n",
    "x_test = pad_sequences(url_test.apply(lambda url: numpy.array([encodeChar(c) for c in url])), \n",
    "              maxlen=maxlen, \n",
    "              padding='pre')\n",
    "\n",
    "x_val = pad_sequences(url_val.apply(lambda url: numpy.array([encodeChar(c) for c in url])), \n",
    "              maxlen=maxlen, \n",
    "              padding='pre')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('x_val shape:', x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"CNN-LSTM for phishing detection\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 400, 128)          12288     \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 396, 64)           41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 198, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 70)                37800     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 71        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 91,183\n",
      "Trainable params: 91,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential(name=\"CNN-LSTM for phishing detection\")\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen, trainable=True))\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=pool_size))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dropout(Dropout_ratio))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# opt = SGD(lr=0.01)\n",
    "# opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "#               optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxcian/dev/python3/env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 22s 4ms/step - loss: 0.4311 - accuracy: 0.7995 - val_loss: 0.2996 - val_accuracy: 0.8855\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 21s 3ms/step - loss: 0.2710 - accuracy: 0.9012 - val_loss: 0.2240 - val_accuracy: 0.9180\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 21s 4ms/step - loss: 0.2411 - accuracy: 0.9142 - val_loss: 0.1988 - val_accuracy: 0.9315\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 22s 4ms/step - loss: 0.2417 - accuracy: 0.9103 - val_loss: 0.2083 - val_accuracy: 0.9230\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 25s 4ms/step - loss: 0.2224 - accuracy: 0.9162 - val_loss: 0.2105 - val_accuracy: 0.9245\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 25s 4ms/step - loss: 0.1805 - accuracy: 0.9343 - val_loss: 0.2237 - val_accuracy: 0.9140\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 25s 4ms/step - loss: 0.1402 - accuracy: 0.9500 - val_loss: 0.1687 - val_accuracy: 0.9395\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 25s 4ms/step - loss: 0.1132 - accuracy: 0.9608 - val_loss: 0.1282 - val_accuracy: 0.9555\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 27s 5ms/step - loss: 0.1318 - accuracy: 0.9548 - val_loss: 0.1740 - val_accuracy: 0.9440\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 25s 4ms/step - loss: 0.1156 - accuracy: 0.9583 - val_loss: 0.1191 - val_accuracy: 0.9625\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 25s 4ms/step - loss: 0.0790 - accuracy: 0.9747 - val_loss: 0.1109 - val_accuracy: 0.9640\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 26s 4ms/step - loss: 0.1041 - accuracy: 0.9630 - val_loss: 0.1364 - val_accuracy: 0.9505\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 25s 4ms/step - loss: 0.0664 - accuracy: 0.9777 - val_loss: 0.2346 - val_accuracy: 0.9280\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 25s 4ms/step - loss: 0.0660 - accuracy: 0.9790 - val_loss: 0.1225 - val_accuracy: 0.9605\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 26s 4ms/step - loss: 0.0584 - accuracy: 0.9795 - val_loss: 0.1179 - val_accuracy: 0.9660\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 26s 4ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 0.1044 - val_accuracy: 0.9685\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 26s 4ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 0.1444 - val_accuracy: 0.9605\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 27s 4ms/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.1283 - val_accuracy: 0.9675\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - 26s 4ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.1195 - val_accuracy: 0.9670\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 27s 4ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.1205 - val_accuracy: 0.9670\n",
      "2000/2000 [==============================] - 2s 959us/step\n",
      "Test score: 0.1391742214858532\n",
      "Test accuracy: 0.9664999842643738\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "#           epochs=3,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 5s 806us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01131321768897275, 0.9965000152587891]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 2s 913us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12048131987452507, 0.9670000076293945]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
